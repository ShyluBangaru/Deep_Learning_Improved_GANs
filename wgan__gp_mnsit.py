# -*- coding: utf-8 -*-
"""WGAN__GP_MNSIT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14Qr51A0qns_ODvPxSROYOZxegOQdS94u
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
from torch_fidelity import calculate_metrics
import numpy as np

# **Device Configuration**
device = torch.device("mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Hyperparameters
latent_dim = 100
img_size = 28
channels = 1
batch_size = 64
num_epochs = 300
learning_rate_g = 0.0002  # Reduced learning rate for generator
learning_rate_d = 0.0003  # Reduced learning rate for discriminator
#weight_clip = 0.01  # Weight clipping value
lambda_gp = 1  # Gradient penalty coefficient

# **Data Loading**
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])  # Normalize images to [-1, 1]
])
dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True if device != "mps" else False)

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.BatchNorm1d(128),
            nn.LeakyReLU(0.2),  # Replaced ReLU with LeakyReLU
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.2),  # Replaced ReLU with LeakyReLU
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(0.2),  # Replaced ReLU with LeakyReLU
            nn.Linear(512, img_size * img_size * channels),
            nn.Tanh()
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), channels, img_size, img_size)
        return img

# **Discriminator (Critic) for WGAN**
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(img_size * img_size * channels, 512),
            nn.LeakyReLU(0.2),  # Replaced ReLU with LeakyReLU
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),  # Replaced ReLU with LeakyReLU
            nn.Linear(256, 1)
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)  # No Sigmoid in WGAN
        return validity

def compute_gradient_penalty(discriminator, real_samples, fake_samples):
    # Random weight term for interpolation
    alpha = torch.randn(real_samples.size(0), 1, 1, 1, device=device)  # Shape [batch_size, 1, 1, 1]
    alpha = alpha.expand_as(real_samples)  # Now it will match the shape of real_samples: [batch_size, 1, 28, 28]

    interpolates = alpha * real_samples + (1 - alpha) * fake_samples
    interpolates.requires_grad_(True)

    d_interpolates = discriminator(interpolates)
    gradients = torch.autograd.grad(outputs=d_interpolates, inputs=interpolates,
                                    grad_outputs=torch.ones(d_interpolates.size(), device=device),
                                    create_graph=True, retain_graph=True, only_inputs=True)[0]

    gradients = gradients.view(gradients.size(0), -1)
    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()  # L2 norm
    return gradient_penalty

# **Model Initialization**
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# **Loss and Optimizers**
criterion = nn.BCEWithLogitsLoss()  # Using BCEWithLogitsLoss for unscaled discriminator output
g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate_g, betas=(0.5, 0.999))
d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate_d, betas=(0.5, 0.999))

d_steps = 10  # Train discriminator more frequently than the generator (1 times per generator step)

for epoch in range(num_epochs):
    for i, (real_images, _) in enumerate(data_loader):
        # Prepare labels
        real_labels = torch.full((real_images.size(0), 1), 0.9, device=device)
        fake_labels = torch.full((real_images.size(0), 1), 0.1, device=device)

        # Move real images to device
        real_images = real_images.to(device)

        # Train the discriminator multiple times
        for _ in range(d_steps):
            noise = torch.randn(real_images.size(0), latent_dim, device=device)
            fake_images = generator(noise).detach()  # Detach to avoid updating generator during discriminator training

            # Compute discriminator loss
            real_images += torch.randn_like(real_images) * 0.05  # Optional noise addition
            fake_images += torch.randn_like(fake_images) * 0.05  # Optional noise addition

            d_real_loss = criterion(discriminator(real_images), real_labels)
            d_fake_loss = criterion(discriminator(fake_images), fake_labels)
            d_loss = d_real_loss + d_fake_loss

            # Compute Gradient Penalty
            gradient_penalty = compute_gradient_penalty(discriminator, real_images, fake_images)
            d_loss += lambda_gp * gradient_penalty

            d_optimizer.zero_grad()
            d_loss.backward()
            d_optimizer.step()

        # **Train Generator**
        noise = torch.randn(real_images.size(0), latent_dim, device=device)
        fake_images = generator(noise)
        g_loss = criterion(discriminator(fake_images), real_labels)  # Use real_labels to fool D

        g_optimizer.zero_grad()
        g_loss.backward()
        g_optimizer.step()



    # Print losses
    print(f"Epoch [{epoch+1}/{num_epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}")

    # Save and visualize generated images every 10 epochs
    if (epoch + 1) % 10 == 0:
        with torch.no_grad():
            noise = torch.randn(64, latent_dim, device=device)
            generated_images = generator(noise).cpu()

            # Plot the images
            fig, axes = plt.subplots(8, 8, figsize=(8, 8))
            for j, ax in enumerate(axes.flatten()):
                ax.imshow(generated_images[j, 0], cmap='gray')
                ax.axis('off')
            plt.show()

# Save generator and discriminator
torch.save(generator.state_dict(), 'generator_model.pth')
torch.save(discriminator.state_dict(), 'discriminator_model.pth')

from torchvision.utils import save_image

import torch
from torch_fidelity import calculate_metrics

# Set device to MPS or CPU fallback
device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')

# Your existing FID calculation code
metrics = calculate_metrics(
    input1=real_images_dir,
    input2=generated_images_dir,
    cuda=False,  # `torch_fidelity` doesn't yet support MPS directly
    isc=False,   # Inception Score not needed
    fid=True     # Compute FID
)
print(f"FID Score: {metrics['frechet_inception_distance']}")

from sklearn.metrics import precision_score, recall_score, accuracy_score

# Evaluate discriminator on test data
def evaluate_discriminator(discriminator, generator, data_loader, device):
    discriminator.eval()
    generator.eval()

    all_preds = []
    all_targets = []

    with torch.no_grad():
        for real_images, _ in data_loader:
            # Prepare real and fake data
            real_images = real_images.to(device)
            batch_size = real_images.size(0)
            noise = torch.randn(batch_size, latent_dim, device=device)
            fake_images = generator(noise)

            # Discriminator predictions
            real_preds = discriminator(real_images).view(-1)
            fake_preds = discriminator(fake_images).view(-1)

            # Convert to binary predictions
            real_labels = torch.ones_like(real_preds, device=device)  # Label 1 for real
            fake_labels = torch.zeros_like(fake_preds, device=device)  # Label 0 for fake

            # Collect predictions and labels
            all_preds.append(torch.cat([real_preds, fake_preds], dim=0).cpu().numpy())
            all_targets.append(torch.cat([real_labels, fake_labels], dim=0).cpu().numpy())

    # Concatenate all predictions and labels
    all_preds = np.concatenate(all_preds)
    all_targets = np.concatenate(all_targets)

    # Apply thresholding for binary classification
    all_preds_binary = (all_preds > 0.5).astype(int)

    # Calculate metrics
    precision = precision_score(all_targets, all_preds_binary)
    recall = recall_score(all_targets, all_preds_binary)
    accuracy = accuracy_score(all_targets, all_preds_binary)

    return precision, recall, accuracy

# Call the function after training
precision, recall, accuracy = evaluate_discriminator(discriminator, generator, data_loader, device)

print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"Accuracy: {accuracy:.4f}")

